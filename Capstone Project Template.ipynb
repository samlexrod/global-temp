{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Pipeline of Global Wold Temperatures\n",
    "## Data Engineering Capstone Project\n",
    "---\n",
    "\n",
    "### Project Summary\n",
    "> The project contains information on how the whole pipeline will look in production. This notebook is designed to test the code to be used in production.\n",
    "\n",
    "The project follows these steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Installations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/bb20f9b9e24f9a6250f95a432f8d9a7d745f8d24039d7a5a6eaadb7783ba/kaggle-1.5.6.tar.gz (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.3MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from kaggle) (1.22)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from kaggle) (1.11.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.6/site-packages (from kaggle) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from kaggle) (2.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from kaggle) (2.18.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from kaggle) (4.11.2)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/92/5f/7b84a0bba8a0fdd50c046f8b57dcf179dc16237ad33446079b7c484de04c/python-slugify-4.0.0.tar.gz\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->kaggle) (2.6)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/a5/c0b6468d3824fe3fde30dbb5e1f687b291608f9473681bbf7dabbf5a87d7/text_unidecode-1.3-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 5.5MB/s ta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
      "  Running setup.py bdist_wheel for kaggle ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/57/4e/e8/bb28d035162fb8f17f8ca5d42c3230e284c6aa565b42b72674\n",
      "  Running setup.py bdist_wheel for python-slugify ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/11/94/81/312969455540cb0e6a773e5d68a73c14128bfdfd4a7969bb4f\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.6 python-slugify-4.0.0 text-unidecode-1.3\n",
      "Collecting twine\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/db/b2c65078b783c6694bdfa0911bbbe0e2be7fcbc98ff23a99b8be544906b6/twine-3.2.0-py3-none-any.whl\n",
      "Collecting requests>=2.20 (from twine)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 5.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting rfc3986>=1.4.0 (from twine)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from twine) (0.9.1)\n",
      "Collecting tqdm>=4.14 (from twine)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/76/4697ce203a3d42b2ead61127b35e5fcc26bba9a35c03b32a2bd342a4c869/tqdm-4.46.1-py2.py3-none-any.whl (63kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 9.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from twine) (38.4.0)\n",
      "Collecting pkginfo>=1.4.2 (from twine)\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/d5/451b913307b478c49eb29084916639dc53a88489b993530fed0a66bab8b9/pkginfo-1.5.0.1-py2.py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from twine)\n",
      "  Downloading https://files.pythonhosted.org/packages/98/13/a1d703ec396ade42c1d33df0e1cb691a28b7c08b336a5683912c87e04cd7/importlib_metadata-1.6.1-py2.py3-none-any.whl\n",
      "Collecting readme-renderer>=21.0 (from twine)\n",
      "  Downloading https://files.pythonhosted.org/packages/54/e4/ed43056d80a4fcc3667e543a59cc6beaf0a3c0eade837e5591e82ad3c25a/readme_renderer-26.0-py2.py3-none-any.whl\n",
      "Collecting keyring>=15.1 (from twine)\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/5e/d13b9feb235d042321a239ac8bc85e90cf3bbe49090c6f1383ac3fd53e0e/keyring-21.2.1-py3-none-any.whl\n",
      "Collecting colorama>=0.4.3 (from twine)\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20->twine) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20->twine) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20->twine) (2.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20->twine) (1.22)\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->twine)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: docutils>=0.13.1 in /opt/conda/lib/python3.6/site-packages (from readme-renderer>=21.0->twine) (0.14)\n",
      "Collecting Pygments>=2.5.1 (from readme-renderer>=21.0->twine)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/68/106af3ae51daf807e9cdcba6a90e518954eb8b70341cee52995540a53ead/Pygments-2.6.1-py3-none-any.whl (914kB)\n",
      "\u001b[K    100% |████████████████████████████████| 921kB 8.6MB/s eta 0:00:01    52% |████████████████▉               | 481kB 10.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bleach>=2.1.0 (from readme-renderer>=21.0->twine)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/1e/7d6cb3b27cd2c490558349ca5d5cc05b390b017da1c704cac807ac8bd9fb/bleach-3.1.5-py2.py3-none-any.whl (151kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 9.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from readme-renderer>=21.0->twine) (1.11.0)\n",
      "Collecting jeepney>=0.4.2; sys_platform == \"linux\" (from keyring>=15.1->twine)\n",
      "  Downloading https://files.pythonhosted.org/packages/79/31/2e8d42727595faf224c6dbb748c32b192e212f25495fe841fb7ce8e168b8/jeepney-0.4.3-py3-none-any.whl\n",
      "Collecting SecretStorage>=3; sys_platform == \"linux\" (from keyring>=15.1->twine)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/50/8a02cad020e949e6d7105f5f4530d41e3febcaa5b73f8f2148aacb3aeba5/SecretStorage-3.1.2-py3-none-any.whl\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from bleach>=2.1.0->readme-renderer>=21.0->twine) (0.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from bleach>=2.1.0->readme-renderer>=21.0->twine) (16.8)\n",
      "Requirement already satisfied: cryptography in /opt/conda/lib/python3.6/site-packages (from SecretStorage>=3; sys_platform == \"linux\"->keyring>=15.1->twine) (2.1.4)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.6/site-packages (from packaging->bleach>=2.1.0->readme-renderer>=21.0->twine) (2.2.0)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /opt/conda/lib/python3.6/site-packages (from cryptography->SecretStorage>=3; sys_platform == \"linux\"->keyring>=15.1->twine) (0.22.0)\n",
      "Requirement already satisfied: cffi>=1.7 in /opt/conda/lib/python3.6/site-packages (from cryptography->SecretStorage>=3; sys_platform == \"linux\"->keyring>=15.1->twine) (1.11.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.7->cryptography->SecretStorage>=3; sys_platform == \"linux\"->keyring>=15.1->twine) (2.18)\n",
      "\u001b[31mmoviepy 0.2.3.2 has requirement tqdm==4.11.2, but you'll have tqdm 4.46.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mawscli 1.16.17 has requirement colorama<=0.3.9,>=0.2.5, but you'll have colorama 0.4.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: requests, rfc3986, tqdm, pkginfo, zipp, importlib-metadata, Pygments, bleach, readme-renderer, jeepney, SecretStorage, keyring, colorama, twine\n",
      "  Found existing installation: requests 2.18.4\n",
      "    Uninstalling requests-2.18.4:\n",
      "      Successfully uninstalled requests-2.18.4\n",
      "  Found existing installation: tqdm 4.11.2\n",
      "    Uninstalling tqdm-4.11.2:\n",
      "      Successfully uninstalled tqdm-4.11.2\n",
      "  Found existing installation: Pygments 2.2.0\n",
      "    Uninstalling Pygments-2.2.0:\n",
      "      Successfully uninstalled Pygments-2.2.0\n",
      "  Found existing installation: bleach 1.5.0\n",
      "    Uninstalling bleach-1.5.0:\n",
      "      Successfully uninstalled bleach-1.5.0\n",
      "  Found existing installation: colorama 0.3.9\n",
      "    Uninstalling colorama-0.3.9:\n",
      "      Successfully uninstalled colorama-0.3.9\n",
      "Successfully installed Pygments-2.6.1 SecretStorage-3.1.2 bleach-3.1.5 colorama-0.4.3 importlib-metadata-1.6.1 jeepney-0.4.3 keyring-21.2.1 pkginfo-1.5.0.1 readme-renderer-26.0 requests-2.24.0 rfc3986-1.4.0 tqdm-4.46.1 twine-3.2.0 zipp-3.1.0\n"
     ]
    }
   ],
   "source": [
    "# Do all imports and installs here\n",
    "!pip install kaggle \n",
    "!pip install twine\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# pyspark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# starting spark application\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "<hr style=\"border-top: 3px double\">\n",
    "Explain what you plan to do in the project in more detail. \n",
    "\n",
    "##### <u>Development Scope</u>\n",
    "In this development notebook, I will use the [Wold Temperature Data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) from kaggle. The data will be stored in the local machine under a folder representing the bucket and keys of s3.\n",
    "\n",
    "##### <u>Production Scope</u>\n",
    "\n",
    "In the production phase, I will use the raw data from the source of truth, which is berkeleyearth.org. We will use AWS Lambda function to gather the data, the EMR to process the cleaning and transformation, and Redshift Spectrum to read the S3 parquet files to connected with either PowerBI or Quicksight for downstream consumption.\n",
    "\n",
    "#### Description of Data\n",
    "<hr style=\"border-top: 2px double\">\n",
    "\n",
    "As they explain in Kaggle, Berkeley Earth Surface Temperature Study combines 1.6 billion temperature reports from 16 pre-existing archives.\n",
    "\n",
    "Global Land and Ocean-and-Land Temperatures (GlobalTemperatures.csv):\n",
    "\n",
    "- Date: starts in 1750 for average land temperature and 1850 for max and min land temperatures and global ocean and land temperatures\n",
    "- LandAverageTemperature: global average land temperature in celsius\n",
    "- LandAverageTemperatureUncertainty: the 95% confidence interval around the average\n",
    "- LandMaxTemperature: global average maximum land temperature in celsius\n",
    "- LandMaxTemperatureUncertainty: the 95% confidence interval around the maximum land temperature\n",
    "- LandMinTemperature: global average minimum land temperature in celsius\n",
    "- LandMinTemperatureUncertainty: the 95% confidence interval around the minimum land temperature\n",
    "- LandAndOceanAverageTemperature: global average land and ocean temperature in celsius\n",
    "- LandAndOceanAverageTemperatureUncertainty: the 95% confidence interval around the global average land and ocean temperature\n",
    "\n",
    "Other files are provided in the following groupings:\n",
    "- Country\n",
    "- State\n",
    "- Major City\n",
    "- City\n",
    "\n",
    "#### Data Gathering \n",
    "<hr style=\"border-top: 2px double\">\n",
    "\n",
    "##### <u>Development Data Gathering</u>\n",
    "As mentioned above, the data will be downloaded from Kaggle.com from theri kaggle cli API for this development process. \n",
    "\n",
    "To connect to the API, we must create a token. This token will allow programatic download of the data in a zip compression format.\n",
    "\n",
    "> An API token was created generating a kaggle.json file. This file was uploaded to /home/workspace\n",
    "\n",
    "##### <u>Production Data Gathering</u>\n",
    "\n",
    "The production version of data gathering will be in an AWS Lambda function that will request the text file from http://berkeleyearth.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Gathering the Data for Development\n",
    "<hr style=\"border-top: 2px double\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reset directory and raw content\n",
    "!rm world-temp-data -r -f\n",
    "!rm climate-change-earth-surface-temperature-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create credential folder\n",
    "!mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the file with token was manualy uploaded\n",
    "!mv /home/workspace/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# securing file to only owner read and write\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                          title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "-----------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "berkeleyearth/climate-change-earth-surface-temperature-data  Climate Change: Earth Surface Temperature Data      85MB  2017-05-01 17:29:10          38220       1075  0.7647059        \n",
      "sumanthvrao/daily-climate-time-series-data                   Daily Climate time series data                      22KB  2019-08-23 09:22:09           1629         35  1.0              \n",
      "theworldbank/world-bank-climate-change-data                  World Bank Climate Change Data                      42MB  2019-05-16 20:00:44           1650         66  0.7058824        \n",
      "jsphyg/weather-dataset-rattle-package                        Rain in Australia                                    4MB  2018-12-03 00:07:10          22693        475  1.0              \n",
      "econdata/climate-change                                      climate change                                       9KB  2019-12-27 05:04:56            309         10  0.5294118        \n",
      "crawford/agricultural-survey-of-african-farm-households      Agricultural Survey of African Farm Households       4MB  2017-07-20 18:07:44           2526         63  0.8235294        \n",
      "brankokokanovic/wiki-climate                                 Wiki climate                                         2MB  2018-10-11 22:37:21            105          2  0.6875           \n",
      "vanshjatana/monsoon-data                                     Climate Data                                       251KB  2018-11-29 06:53:22             60         13  0.29411766       \n",
      "brunotly/climate-change                                      Climate Change                                       1MB  2020-03-01 17:20:38             62          5  0.47058824       \n",
      "edqian/twitter-climate-change-sentiment-dataset              Twitter Climate Change Sentiment Dataset             2MB  2019-11-13 00:28:07            343         16  0.9411765        \n",
      "rainbowgirl/climate-data-toronto-19372018                    Climate Data Toronto 1937-2018                      31KB  2018-12-04 00:15:45            715         14  0.3529412        \n",
      "dbialer/svalbard-climate-19102017                            Svalbard Climate, 1910-2017                          3KB  2017-09-11 20:54:24            208          8  0.7647059        \n",
      "sudalairajkumar/daily-temperature-of-major-cities            Daily Temperature of Major Cities                   13MB  2020-06-05 07:34:48           2221        108  1.0              \n",
      "noaa/global-historical-climatology-network                   Global Historical Climatology Network                5MB  2016-10-24 15:23:05           2094         51  0.7058824        \n",
      "reubencpereira/spatial-data-repo                             Spatial Data Repository (satellite data and more)   63MB  2018-05-15 18:46:08            615         32  0.7058824        \n",
      "aturner374/eighty-years-of-canadian-climate-data             Eighty years of Canadian climate data              991KB  2020-01-27 19:28:52            106          6  0.9117647        \n",
      "atulanandjha/temperature-readings-iot-devices                Temperature Readings : IOT Devices                   1MB  2019-12-01 18:48:54           2048         91  1.0              \n",
      "nsidcorg/daily-sea-ice-extent-data                           Daily Sea Ice Extent Data                          233KB  2019-06-10 18:42:01            695         71  0.7647059        \n",
      "mathijs/weather-data-in-new-york-city-2016                   Weather data in New York City - 2016                 3KB  2017-09-24 18:06:20           5399         70  0.5882353        \n",
      "sohier/calcofi                                               CalCOFI                                             50MB  2017-08-23 19:24:53           8721        150  0.85294116       \n",
      "/bin/sh: 1: change: not found\n"
     ]
    }
   ],
   "source": [
    "# listing datasets that contains climate and change\n",
    "!kaggle datasets list -s climate && change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading climate-change-earth-surface-temperature-data.zip to /home/workspace\n",
      " 83%|███████████████████████████████▍      | 70.0M/84.7M [00:00<00:00, 66.0MB/s]\n",
      "100%|███████████████████████████████████████| 84.7M/84.7M [00:00<00:00, 109MB/s]\n"
     ]
    }
   ],
   "source": [
    "# downloading the zip file\n",
    "!kaggle datasets download -d berkeleyearth/climate-change-earth-surface-temperature-data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# unziping the downloaded file into wold_temp_date\n",
    "zip_file = ZipFile(\"climate-change-earth-surface-temperature-data.zip\", mode=\"r\")\n",
    "zip_file.extractall(\"s3/world-temp-data/csv-files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Read all Flat File Datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- LandAverageTemperature: double (nullable = true)\n",
      " |-- LandAverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMaxTemperature: double (nullable = true)\n",
      " |-- LandMaxTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMinTemperature: double (nullable = true)\n",
      " |-- LandMinTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperature: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperatureUncertainty: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_global = spark.read.csv(\"s3/world-temp-data/csv-files/GlobalTemperatures.csv\", header=True, inferSchema=True)\n",
    "df_global.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_bycity = spark.read.csv(\"s3/world-temp-data/csv-files/GlobalLandTemperaturesByCity.csv\", header=True, inferSchema=True)\n",
    "df_bycountry = spark.read.csv(\"s3/world-temp-data/csv-files/GlobalLandTemperaturesByCountry.csv\", header=True, inferSchema=True)\n",
    "df_bymajorcity = spark.read.csv(\"s3/world-temp-data/csv-files/GlobalLandTemperaturesByMajorCity.csv\", header=True, inferSchema=True)\n",
    "df_bystate = spark.read.csv(\"s3/world-temp-data/csv-files/GlobalLandTemperaturesByState.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Showing and Explaining the Individual Datasets\n",
    "<hr style=\"border-top: 2px double\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <ol style=\"display: inline-block\"><li> Global Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>1750-01-01 00:00:00</td>\n",
       "      <td>1750-02-01 00:00:00</td>\n",
       "      <td>1750-03-01 00:00:00</td>\n",
       "      <td>1750-04-01 00:00:00</td>\n",
       "      <td>1750-05-01 00:00:00</td>\n",
       "      <td>1750-06-01 00:00:00</td>\n",
       "      <td>1750-07-01 00:00:00</td>\n",
       "      <td>1750-08-01 00:00:00</td>\n",
       "      <td>1750-09-01 00:00:00</td>\n",
       "      <td>1750-10-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandAverageTemperature</th>\n",
       "      <td>3.034</td>\n",
       "      <td>3.083</td>\n",
       "      <td>5.626</td>\n",
       "      <td>8.49</td>\n",
       "      <td>11.573</td>\n",
       "      <td>12.937</td>\n",
       "      <td>15.868</td>\n",
       "      <td>14.75</td>\n",
       "      <td>11.413</td>\n",
       "      <td>6.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandAverageTemperatureUncertainty</th>\n",
       "      <td>3.574</td>\n",
       "      <td>3.702</td>\n",
       "      <td>3.076</td>\n",
       "      <td>2.451</td>\n",
       "      <td>2.072</td>\n",
       "      <td>1.724</td>\n",
       "      <td>1.911</td>\n",
       "      <td>2.231</td>\n",
       "      <td>2.637</td>\n",
       "      <td>2.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandMaxTemperature</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandMaxTemperatureUncertainty</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandMinTemperature</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandMinTemperatureUncertainty</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandAndOceanAverageTemperature</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandAndOceanAverageTemperatureUncertainty</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             0  \\\n",
       "dt                                         1750-01-01 00:00:00   \n",
       "LandAverageTemperature                                   3.034   \n",
       "LandAverageTemperatureUncertainty                        3.574   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             1  \\\n",
       "dt                                         1750-02-01 00:00:00   \n",
       "LandAverageTemperature                                   3.083   \n",
       "LandAverageTemperatureUncertainty                        3.702   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             2  \\\n",
       "dt                                         1750-03-01 00:00:00   \n",
       "LandAverageTemperature                                   5.626   \n",
       "LandAverageTemperatureUncertainty                        3.076   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             3  \\\n",
       "dt                                         1750-04-01 00:00:00   \n",
       "LandAverageTemperature                                    8.49   \n",
       "LandAverageTemperatureUncertainty                        2.451   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             4  \\\n",
       "dt                                         1750-05-01 00:00:00   \n",
       "LandAverageTemperature                                  11.573   \n",
       "LandAverageTemperatureUncertainty                        2.072   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             5  \\\n",
       "dt                                         1750-06-01 00:00:00   \n",
       "LandAverageTemperature                                  12.937   \n",
       "LandAverageTemperatureUncertainty                        1.724   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             6  \\\n",
       "dt                                         1750-07-01 00:00:00   \n",
       "LandAverageTemperature                                  15.868   \n",
       "LandAverageTemperatureUncertainty                        1.911   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             7  \\\n",
       "dt                                         1750-08-01 00:00:00   \n",
       "LandAverageTemperature                                   14.75   \n",
       "LandAverageTemperatureUncertainty                        2.231   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             8  \\\n",
       "dt                                         1750-09-01 00:00:00   \n",
       "LandAverageTemperature                                  11.413   \n",
       "LandAverageTemperatureUncertainty                        2.637   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             9  \n",
       "dt                                         1750-10-01 00:00:00  \n",
       "LandAverageTemperature                                   6.367  \n",
       "LandAverageTemperatureUncertainty                        2.668  \n",
       "LandMaxTemperature                                        None  \n",
       "LandMaxTemperatureUncertainty                             None  \n",
       "LandMinTemperature                                        None  \n",
       "LandMinTemperatureUncertainty                             None  \n",
       "LandAndOceanAverageTemperature                            None  \n",
       "LandAndOceanAverageTemperatureUncertainty                 None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_global.limit(10).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> This dataset describes the global temperatures on a time series basis. It also includes descriptive and inferential statistics about the global average. It is useful to compare global temperatures with temperatures by country to find countries that are outliers in our analysis of climate change.\n",
    "<hr style=\"border-top: 2px dotted; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <ol start=\"2\" style=\"display: inline-block\"><li> By City Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01 00:00:00|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bycity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> This dataset describes the global temperatures by city. It can be used to forecast the temperatures by city or to investigate global temperature abnormalies by city.\n",
    "<hr style=\"border-top: 2px dotted; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <ol start=\"3\" style=\"display: inline-block\"><li>By Country Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty|Country|\n",
      "+-------------------+------------------+-----------------------------+-------+\n",
      "|1743-11-01 00:00:00|4.3839999999999995|                        2.294|  Åland|\n",
      "|1743-12-01 00:00:00|              null|                         null|  Åland|\n",
      "|1744-01-01 00:00:00|              null|                         null|  Åland|\n",
      "|1744-02-01 00:00:00|              null|                         null|  Åland|\n",
      "|1744-03-01 00:00:00|              null|                         null|  Åland|\n",
      "+-------------------+------------------+-----------------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bycountry.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> This dataset describes the global temperatures by country. It can be used to forecast the temperatures by city or to investigate global temperature abnormalies by country.\n",
    "<hr style=\"border-top: 2px dotted; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <ol start=\"4\" style=\"display: inline-block\"><li>By Major City Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty|   City|      Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "|1849-01-01 00:00:00|            26.704|                        1.435|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-02-01 00:00:00|            27.434|                        1.362|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-03-01 00:00:00|            28.101|                        1.612|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-04-01 00:00:00|             26.14|           1.3869999999999998|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-05-01 00:00:00|            25.427|                          1.2|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "+-------------------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bymajorcity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> This dataset describes the global temperatures by major city. It can be used to forecast the temperatures by city or to investigate global temperature abnormalies by major city.\n",
    "<hr style=\"border-top: 2px dotted; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <ol start=\"5\" style=\"display: inline-block\"><li>By State Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----+-------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty|State|Country|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+\n",
      "|1855-05-01 00:00:00|            25.544|                        1.171| Acre| Brazil|\n",
      "|1855-06-01 00:00:00|            24.228|                        1.103| Acre| Brazil|\n",
      "|1855-07-01 00:00:00|            24.371|                        1.044| Acre| Brazil|\n",
      "|1855-08-01 00:00:00|            25.427|                        1.073| Acre| Brazil|\n",
      "|1855-09-01 00:00:00|            25.675|                        1.014| Acre| Brazil|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bystate.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> This dataset describes the global temperatures by state. It can be used to forecast the temperatures by city or to investigate global temperature abnormalies by state.\n",
    "<hr style=\"border-top: 2px dotted; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Converting and Reading Parquet\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Converting CSV to Parquet \n",
    "Apache Parquet is a columnar file format that provides optimizations to speed up queries and is a far more efficient file format than CSV or JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_global.write.parquet(\"s3/world-temp-data/parquet-staging/GlobalTemperatures\", mode=\"overwrite\")\n",
    "df_bycity.write.parquet(\"s3/world-temp-data/parquet-staging/GlobalLandTemperaturesByCity\", mode=\"overwrite\")\n",
    "df_bycountry.write.parquet(\"s3/world-temp-data/parquet-staging/GlobalLandTemperaturesByCountry\", mode=\"overwrite\")\n",
    "df_bymajorcity.write.parquet(\"s3/world-temp-data/parquet-staging/GlobalLandTemperaturesByMajorCity\", mode=\"overwrite\")\n",
    "df_bystate.write.parquet(\"s3/world-temp-data/parquet-staging/GlobalLandTemperaturesByState\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_global = spark.read.parquet(\"s3/world-temp-data/parquet-staging/GlobalTemperatures\")\n",
    "df_bycity = spark.read.parquet(\"s3/world-temp-data/parquet-staging/GlobalLandTemperaturesByCity\")\n",
    "df_bycountry = spark.read.parquet(\"s3/world-temp-data/parquet-staging/GlobalLandTemperaturesByCountry\")\n",
    "df_bymajorcity = spark.read.parquet(\"s3/world-temp-data/parquet-staging/GlobalLandTemperaturesByMajorCity\")\n",
    "df_bystate = spark.read.parquet(\"s3/world-temp-data/parquet-staging/GlobalLandTemperaturesByState\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Exploring Parquet Data\n",
    "---\n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def explore(dataframe, show_affected=False):\n",
    "    \"\"\"\n",
    "    This function explores the transposed content of a dataset,\n",
    "    the schema, and the null percentages\n",
    "    \"\"\"\n",
    "    df = dataframe    \n",
    "    null_expr = [f\"SUM(CASE WHEN {x} IS NULL THEN 1 ELSE 0 END) AS null_{x}\" for x in df.columns]\n",
    "    df_pd = (\n",
    "        df.selectExpr(null_expr)\n",
    "            .toPandas()\n",
    "            .transpose()\n",
    "            .rename(columns={0: 'nulls'})\n",
    "            .assign(null_pct= lambda x: x.nulls / df.count())\n",
    "    )    \n",
    "    display(df_pd.style.format({'nulls': '{:d}', 'null_pct': '{:2.2%}'}))\n",
    "    df.printSchema()\n",
    "    \n",
    "    if show_affected:\n",
    "        (df.where(F.col('dt').isin(affected_dates))\n",
    "             .groupBy('dt')\n",
    "             .agg(\n",
    "                F.expr('sum(AverageTemperature) AS affectedAverageTemperature'),\n",
    "                F.expr('sum(AverageTemperatureUncertainty) AS affectedAverageTemperatureUncertainty')\n",
    "             ).orderBy(F.desc('dt'))\n",
    "        ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "affected_dates = df_global.where(F.col('LandAverageTemperature').isNull()).select('dt').collect()\n",
    "affected_dates = [x.asDict().get('dt') for x in affected_dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <ol start=\"1\" style=\"display: inline-block\"><li> Exploring Global Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_97b99730_b67b_11ea_9298_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_97b99730_b67b_11ea_9298_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_97b99730_b67b_11ea_9298_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_LandAverageTemperature</th> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row1_col0\" class=\"data row1 col0\" >12</td> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row1_col1\" class=\"data row1 col1\" >0.38%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_97b99730_b67b_11ea_9298_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_LandAverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row2_col0\" class=\"data row2 col0\" >12</td> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row2_col1\" class=\"data row2 col1\" >0.38%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_97b99730_b67b_11ea_9298_0242ac120002level0_row3\" class=\"row_heading level0 row3\" >null_LandMaxTemperature</th> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row3_col0\" class=\"data row3 col0\" >1200</td> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row3_col1\" class=\"data row3 col1\" >37.59%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_97b99730_b67b_11ea_9298_0242ac120002level0_row4\" class=\"row_heading level0 row4\" >null_LandMaxTemperatureUncertainty</th> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row4_col0\" class=\"data row4 col0\" >1200</td> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row4_col1\" class=\"data row4 col1\" >37.59%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_97b99730_b67b_11ea_9298_0242ac120002level0_row5\" class=\"row_heading level0 row5\" >null_LandMinTemperature</th> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row5_col0\" class=\"data row5 col0\" >1200</td> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row5_col1\" class=\"data row5 col1\" >37.59%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_97b99730_b67b_11ea_9298_0242ac120002level0_row6\" class=\"row_heading level0 row6\" >null_LandMinTemperatureUncertainty</th> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row6_col0\" class=\"data row6 col0\" >1200</td> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row6_col1\" class=\"data row6 col1\" >37.59%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_97b99730_b67b_11ea_9298_0242ac120002level0_row7\" class=\"row_heading level0 row7\" >null_LandAndOceanAverageTemperature</th> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row7_col0\" class=\"data row7 col0\" >1200</td> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row7_col1\" class=\"data row7 col1\" >37.59%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_97b99730_b67b_11ea_9298_0242ac120002level0_row8\" class=\"row_heading level0 row8\" >null_LandAndOceanAverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row8_col0\" class=\"data row8 col0\" >1200</td> \n",
       "        <td id=\"T_97b99730_b67b_11ea_9298_0242ac120002row8_col1\" class=\"data row8 col1\" >37.59%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd9497ebda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- LandAverageTemperature: double (nullable = true)\n",
      " |-- LandAverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMaxTemperature: double (nullable = true)\n",
      " |-- LandMaxTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMinTemperature: double (nullable = true)\n",
      " |-- LandMinTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperature: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperatureUncertainty: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <ol start=\"2\" style=\"display: inline-block\"><li> Exploring By City Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_AverageTemperature</th> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row1_col0\" class=\"data row1 col0\" >364130</td> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row1_col1\" class=\"data row1 col1\" >4.23%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_AverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row2_col0\" class=\"data row2 col0\" >364130</td> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row2_col1\" class=\"data row2 col1\" >4.23%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002level0_row3\" class=\"row_heading level0 row3\" >null_City</th> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row3_col0\" class=\"data row3 col0\" >0</td> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row3_col1\" class=\"data row3 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002level0_row4\" class=\"row_heading level0 row4\" >null_Country</th> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row4_col0\" class=\"data row4 col0\" >0</td> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row4_col1\" class=\"data row4 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002level0_row5\" class=\"row_heading level0 row5\" >null_Latitude</th> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row5_col0\" class=\"data row5 col0\" >0</td> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row5_col1\" class=\"data row5 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002level0_row6\" class=\"row_heading level0 row6\" >null_Longitude</th> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row6_col0\" class=\"data row6 col0\" >0</td> \n",
       "        <td id=\"T_9bfcf1c0_b67b_11ea_9298_0242ac120002row6_col1\" class=\"data row6 col1\" >0.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd91b91d390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|                 dt|affectedAverageTemperature|affectedAverageTemperatureUncertainty|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|1752-09-01 00:00:00|                      null|                                 null|\n",
      "|1752-08-01 00:00:00|                      null|                                 null|\n",
      "|1752-07-01 00:00:00|                      null|                                 null|\n",
      "|1752-06-01 00:00:00|                      null|                                 null|\n",
      "|1752-05-01 00:00:00|                      null|                                 null|\n",
      "|1752-02-01 00:00:00|                      null|                                 null|\n",
      "|1751-12-01 00:00:00|                      null|                                 null|\n",
      "|1751-11-01 00:00:00|                      null|                                 null|\n",
      "|1751-10-01 00:00:00|                      null|                                 null|\n",
      "|1751-07-01 00:00:00|        13374.689000000031|                    946.7930000000013|\n",
      "|1751-05-01 00:00:00|                      null|                                 null|\n",
      "|1750-11-01 00:00:00|                      null|                                 null|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_bycity, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <ol start=\"3\" style=\"display: inline-block\"><li> Exploring By Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_AverageTemperature</th> \n",
       "        <td id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002row1_col0\" class=\"data row1 col0\" >32651</td> \n",
       "        <td id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002row1_col1\" class=\"data row1 col1\" >5.65%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_AverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002row2_col0\" class=\"data row2 col0\" >31912</td> \n",
       "        <td id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002row2_col1\" class=\"data row2 col1\" >5.53%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002level0_row3\" class=\"row_heading level0 row3\" >null_Country</th> \n",
       "        <td id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002row3_col0\" class=\"data row3 col0\" >0</td> \n",
       "        <td id=\"T_a221a9c4_b67b_11ea_9298_0242ac120002row3_col1\" class=\"data row3 col1\" >0.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd91b648470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|                 dt|affectedAverageTemperature|affectedAverageTemperatureUncertainty|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|1752-09-01 00:00:00|                      null|                                 null|\n",
      "|1752-08-01 00:00:00|                      null|                                 null|\n",
      "|1752-07-01 00:00:00|                      null|                                 null|\n",
      "|1752-06-01 00:00:00|                      null|                                 null|\n",
      "|1752-05-01 00:00:00|                      null|                                 null|\n",
      "|1752-02-01 00:00:00|                      null|                                 null|\n",
      "|1751-12-01 00:00:00|                      null|                                 null|\n",
      "|1751-11-01 00:00:00|                      null|                                 null|\n",
      "|1751-10-01 00:00:00|                      null|                                 null|\n",
      "|1751-07-01 00:00:00|         905.6660000000003|                               94.739|\n",
      "|1751-05-01 00:00:00|                      null|                                 null|\n",
      "|1750-11-01 00:00:00|                      null|                                 null|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_bycountry, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <ol start=\"4\" style=\"display: inline-block\"><li> Exploring By Major City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_a4346f30_b67b_11ea_9298_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_a4346f30_b67b_11ea_9298_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a4346f30_b67b_11ea_9298_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_AverageTemperature</th> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row1_col0\" class=\"data row1 col0\" >11002</td> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row1_col1\" class=\"data row1 col1\" >4.60%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a4346f30_b67b_11ea_9298_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_AverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row2_col0\" class=\"data row2 col0\" >11002</td> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row2_col1\" class=\"data row2 col1\" >4.60%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a4346f30_b67b_11ea_9298_0242ac120002level0_row3\" class=\"row_heading level0 row3\" >null_City</th> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row3_col0\" class=\"data row3 col0\" >0</td> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row3_col1\" class=\"data row3 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a4346f30_b67b_11ea_9298_0242ac120002level0_row4\" class=\"row_heading level0 row4\" >null_Country</th> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row4_col0\" class=\"data row4 col0\" >0</td> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row4_col1\" class=\"data row4 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a4346f30_b67b_11ea_9298_0242ac120002level0_row5\" class=\"row_heading level0 row5\" >null_Latitude</th> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row5_col0\" class=\"data row5 col0\" >0</td> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row5_col1\" class=\"data row5 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a4346f30_b67b_11ea_9298_0242ac120002level0_row6\" class=\"row_heading level0 row6\" >null_Longitude</th> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row6_col0\" class=\"data row6 col0\" >0</td> \n",
       "        <td id=\"T_a4346f30_b67b_11ea_9298_0242ac120002row6_col1\" class=\"data row6 col1\" >0.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd91b64de10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|                 dt|affectedAverageTemperature|affectedAverageTemperatureUncertainty|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|1752-09-01 00:00:00|                      null|                                 null|\n",
      "|1752-08-01 00:00:00|                      null|                                 null|\n",
      "|1752-07-01 00:00:00|                      null|                                 null|\n",
      "|1752-06-01 00:00:00|                      null|                                 null|\n",
      "|1752-05-01 00:00:00|                      null|                                 null|\n",
      "|1752-02-01 00:00:00|                      null|                                 null|\n",
      "|1751-12-01 00:00:00|                      null|                                 null|\n",
      "|1751-11-01 00:00:00|                      null|                                 null|\n",
      "|1751-10-01 00:00:00|                      null|                                 null|\n",
      "|1751-07-01 00:00:00|                   262.498|                               18.299|\n",
      "|1751-05-01 00:00:00|                      null|                                 null|\n",
      "|1750-11-01 00:00:00|                      null|                                 null|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_bymajorcity, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <ol start=\"5\" style=\"display: inline-block\"><li> Exploring By State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_AverageTemperature</th> \n",
       "        <td id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002row1_col0\" class=\"data row1 col0\" >25648</td> \n",
       "        <td id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002row1_col1\" class=\"data row1 col1\" >3.97%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_AverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002row2_col0\" class=\"data row2 col0\" >25648</td> \n",
       "        <td id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002row2_col1\" class=\"data row2 col1\" >3.97%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002level0_row3\" class=\"row_heading level0 row3\" >null_State</th> \n",
       "        <td id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002row3_col0\" class=\"data row3 col0\" >0</td> \n",
       "        <td id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002row3_col1\" class=\"data row3 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002level0_row4\" class=\"row_heading level0 row4\" >null_Country</th> \n",
       "        <td id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002row4_col0\" class=\"data row4 col0\" >0</td> \n",
       "        <td id=\"T_a60c2fdc_b67b_11ea_9298_0242ac120002row4_col1\" class=\"data row4 col1\" >0.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd91b648da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|                 dt|affectedAverageTemperature|affectedAverageTemperatureUncertainty|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|1752-09-01 00:00:00|                      null|                                 null|\n",
      "|1752-08-01 00:00:00|                      null|                                 null|\n",
      "|1752-07-01 00:00:00|                      null|                                 null|\n",
      "|1752-06-01 00:00:00|                      null|                                 null|\n",
      "|1752-05-01 00:00:00|                      null|                                 null|\n",
      "|1752-02-01 00:00:00|                      null|                                 null|\n",
      "|1751-12-01 00:00:00|                      null|                                 null|\n",
      "|1751-11-01 00:00:00|                      null|                                 null|\n",
      "|1751-10-01 00:00:00|                      null|                                 null|\n",
      "|1751-07-01 00:00:00|        1443.5569999999996|                   210.96800000000005|\n",
      "|1751-05-01 00:00:00|                      null|                                 null|\n",
      "|1750-11-01 00:00:00|                      null|                                 null|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_bystate, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Analsysis**\n",
    "> There are too many nulls in other than LandAverageTemperature and LandAverageTemperatureUncertainty. For our analysis there is also no use for the other columns. Therefore, those columns will be ignored.\n",
    "\n",
    "> Using the same affected dates to impute missing values to the global dataset from grouped datasets will not work since they are affected the same way. Regardless, the addition of the averages will not equal the true missing global average.\n",
    "\n",
    "> For LandAverageTemperature and LandAverageTemperatureUncertainty, we will use the average of the previous values and the next values that approximate the affected nulled ranges. E.g. if the current null value is followed by 2 nulls, we will use the next 3 values and the last 3 values to calculate the average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Cleaning Stage\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The globaltemperatures dataset seems to be fairly clean. However, these are averages, and we still have the questions if the averages are representable of all countries and states within those countries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Imputation if Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_global.createOrReplaceTempView('globaltemps')\n",
    "\n",
    "df_global_clean = spark.sql(\"\"\"\n",
    "WITH cte_null_impute AS (\n",
    "SELECT\n",
    "    dt\n",
    "    ,LandAverageTemperature\n",
    "    ,AVG(LandAverageTemperature) OVER(ORDER BY dt ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING) AS preced_follow_avgtemp\n",
    "    ,LandAverageTemperatureUncertainty\n",
    "    ,AVG(LandAverageTemperatureUncertainty) OVER(ORDER BY dt ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING) AS preced_follow_avgunctemp\n",
    "FROM globaltemps\n",
    ")\n",
    "SELECT \n",
    "    dt\n",
    "    ,COALESCE(LandAverageTemperature, preced_follow_avgtemp) AS LandAverageTemperature\n",
    "    ,COALESCE(LandAverageTemperatureUncertainty, preced_follow_avgunctemp) AS LandAverageTemperatureUncertainty\n",
    "FROM cte_null_impute\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_b54c5ef4_b67b_11ea_9298_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_b54c5ef4_b67b_11ea_9298_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_b54c5ef4_b67b_11ea_9298_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_b54c5ef4_b67b_11ea_9298_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_b54c5ef4_b67b_11ea_9298_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_LandAverageTemperature</th> \n",
       "        <td id=\"T_b54c5ef4_b67b_11ea_9298_0242ac120002row1_col0\" class=\"data row1 col0\" >0</td> \n",
       "        <td id=\"T_b54c5ef4_b67b_11ea_9298_0242ac120002row1_col1\" class=\"data row1 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_b54c5ef4_b67b_11ea_9298_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_LandAverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_b54c5ef4_b67b_11ea_9298_0242ac120002row2_col0\" class=\"data row2 col0\" >0</td> \n",
       "        <td id=\"T_b54c5ef4_b67b_11ea_9298_0242ac120002row2_col1\" class=\"data row2 col1\" >0.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd949837a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- LandAverageTemperature: double (nullable = true)\n",
      " |-- LandAverageTemperatureUncertainty: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_global_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "![conceptual data model](resources/udacity-dend-datamodel.png)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Data is crawled form original  http://berkeleyearth.org website using AWS Lambda\n",
    "2. Data is dumped into a s3 bucket in csv format in s3://world-temp-data/csv-files\n",
    "3. Data is read using a spark cluster using pyspark and converted into parquet in s3://world-temp-data/parquet-staging\n",
    "4. Data is read using a spark cluster using pyspark and transformed/cleaned\n",
    "5. Data is check for null values and duplicates using a spark cluster\n",
    "6. Quality checks are conducted:\n",
    "    a. If data pass all quality checks, it is dumped into into s3://world-temp-data/parquet-clean as parquet\n",
    "    b. If data does not pass quality checks, the error is sent by email to users and the process stops\n",
    "7. A Glue crawler catalogs the parquet files in s3://world-temp-data/parquet-clean as parquet in the Glue global_temp database\n",
    "8. Redshift Spectrum refers to the clean-data table in the global_temp database in a global_temp_db redshift database\n",
    "9. Power BI connects to Redshift and extracts the clean-data table from the global_temp_db using a Redshift Driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 1: AWS Lmabda Crawler\n",
    "> We are extracting data from the website using a Python request package. The outputs will be parsed as csv documents that will be stored in S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 2: Glue Spark Job or EMR Spark Job to Read Csv\n",
    "> The CSV data will be read using spark into a spark dataframe in EMR memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 3: Glue Spark Job or EMR Spark Job to Convert to Parquet\n",
    "> The EMR dataframe in memory is then converted to parquet to consume less resources when conducting transformations and cleaning activities. This step is separated from the rest because we would like to know if the transformation was succesful and the cleaning script runs without any issues. It would also let us know if we have already extracted the same date by the partition provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 4: EMR Job to Read Parquet and Clean Data\n",
    "> We are reading the parquet files and conducting the cleaning on parquet data since it is more efficient. This task will conbine reading parquet and celaning because we are not expecting the reading part to fail. On the contrary, we can expect the cleaning part to fail. Therefore we will know that the cleaning script needs to be evaluated for quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Reading parquet file\n",
    "df = spark.read.parquet(\"s3/world-temp-data/parquet-staging/GlobalTemperatures\")\n",
    "\n",
    "## Cleaning parquet file\n",
    "df.createOrReplaceTempView('staging')\n",
    "\n",
    "df = spark.sql(\"\"\"\n",
    "WITH cte_null_impute AS (\n",
    "SELECT\n",
    "    dt\n",
    "    ,LandAverageTemperature\n",
    "    ,AVG(LandAverageTemperature) OVER(ORDER BY dt ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING) AS preced_follow_avgtemp\n",
    "    ,LandAverageTemperatureUncertainty\n",
    "    ,AVG(LandAverageTemperatureUncertainty) OVER(ORDER BY dt ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING) AS preced_follow_avgunctemp\n",
    "FROM staging\n",
    ")\n",
    "SELECT \n",
    "    dt\n",
    "    ,COALESCE(LandAverageTemperature, preced_follow_avgtemp) AS LandAverageTemperature\n",
    "    ,COALESCE(LandAverageTemperatureUncertainty, preced_follow_avgunctemp) AS LandAverageTemperatureUncertainty\n",
    "FROM cte_null_impute\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 5: Glue Spark Job or EMR Spark Job to Check for Nulls and Duplicates\n",
    "> In this task we are doing to determine if the data is ready for downstream consumption and meets the quality requirements agreed. It is a separate task because we need to make sure that our downstream users are not consuming the wrong data.\n",
    "\n",
    "> The data quality checks performed below will be converted to Redshift postgress sql format to be used in an Airflow dag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## conduct null data quality\n",
    "column_wide_null_count = sum(df.selectExpr(\n",
    "    \"CASE WHEN LandAverageTemperature IS NULL THEN 1 ELSE 0 END AS null_LandAverageTemperature\",\n",
    "    \"CASE WHEN LandAverageTemperatureUncertainty IS NULL THEN 1 ELSE 0 END AS null_LandAverageTemperatureUncertainty\").collect()[0])\n",
    "\n",
    "## conduct duplicate data quality\n",
    "duplicate_count = df.groupBy('dt').agg((F.count('dt')>1).alias('group_count')).where(F.col('group_count')).count()\n",
    "\n",
    "error_list = []\n",
    "if column_wide_null_count > 0:\n",
    "    error_list.append(\"Null where found in the data\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    error_list.append(\"Duplicates where found in the data\")\n",
    "    \n",
    "if len(error_list) > 0:\n",
    "    raise ValueError(' and '.join(error_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 6: Glue Spark Job or EMR Spark Job to Dump Clean Data and Crawled for Downstream\n",
    "> Here we are dumping the data that passess quality checks into the final bucket that will be catalogued using Glue and read using Redshift Spectrum as the endpoint of the visualization tool.\n",
    "\n",
    "> A Glue crawler will catalog the clean data after it is dumped in the destination s3 object/key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Dumping clean dataset into the clean key\n",
    "df.write.parquet(\"s3/world-temp-data/parquet-clean/global-temperatures\")\n",
    "\n",
    "# Done! Data is ready for visualization and forecasting model ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "\n",
    "> The data will be checked right after the data is cleaned. We are preventing bad data from being dumped in the s3://udacity-dend-samuel/clean-data/global-temperatures file key.\n",
    "\n",
    "Thes checks include:\n",
    "* Null checks for both LandAverageTemperature and LandAverageTemperatureUncertainty\n",
    "* Duplicate checks on dt\n",
    "\n",
    "> Another worthy quality check is to make sure data is catalogued in Glue. This one will run in Redshift Sepctrum and it will check for the quantity of rows in the prod.global_temperatures table that Redshift Spectrum reads from the s3://world-temp-data/parquet-clean/global-temperatures file key using the Glue catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here is an example of how the data quality operator will look:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "airflow/operators.py\n",
    "```python\n",
    "from airflow.hooks.postgres_hook import PostgresHook\n",
    "from airflow.models import BaseOperator\n",
    "from airflow.utils.decorators import apply_defaults\n",
    "\n",
    "class NullQualityOperator(BaseOperator):\n",
    "    ui_color = '#89DA59'\n",
    "\n",
    "    @apply_defaults\n",
    "    def __init__(self,\n",
    "                 redshift_conn_id,\n",
    "                 table_name,\n",
    "                 grouping,\n",
    "                 *args, **kwargs):\n",
    "\n",
    "        super(DataQualityOperator, self).__init__(*args, **kwargs)\n",
    "        self.redshift_conn_id = redshift_conn_id\n",
    "        self.table_name = table_name\n",
    "        self.grouping = grouping\n",
    "\n",
    "    def execute(self, context):\n",
    "        redshift = PostgresHook(postgres_conn_id=self.redshift_conn_id)\n",
    "        table_name = self.table_name\n",
    "        grouping = self.grouping\n",
    "        null_exist_query = f\"\"\"\n",
    "            SELECT \n",
    "                SUM(CASE WHEN LandAverageTemperature IS NULL THEN 1 ELSE 0 END) AS null_LandAverageTemperature\n",
    "            FROM {table_name}\n",
    "            \"\"\"\n",
    "        null_exist_query2 = f\"\"\"\n",
    "            SELECT \n",
    "                SUM(CASE WHEN LandAverageTemperatureUncertainty IS NULL THEN 1 ELSE 0 END) AS null_LandAverageTemperatureUncertainty\n",
    "            FROM {table_name}\n",
    "            \"\"\"\n",
    "        \n",
    "        dupliate_exist_query = f\"\"\"\n",
    "            WITH duplicates AS (\n",
    "                SELECT \n",
    "                    dt\n",
    "                FROM {table_name}\n",
    "                GROUP BY {grouping}\n",
    "                HAVING COUNT(1) > 1\n",
    "            )\n",
    "            SELECT COUNT(1) AS duplicate_count\n",
    "            FROM duplicates\n",
    "        \"\"\"\n",
    "        \n",
    "        self.log.info(f\"Conducting data quality on table {table_name}\")\n",
    "        records = redshift.get_records(null_exist_query)\n",
    "        records2 = redshift.get_records(null_exist_query2)\n",
    "        duplicate = redshift.get_records(dupliate_exist_query)\n",
    "        \n",
    "        if len(records) < 1 or len(records[0]) < 1:\n",
    "            raise ValueError(f\"Data quality check failed. The {table_name} table might have no data.\")\n",
    "        \n",
    "        num_records = records[0][0]        \n",
    "        if num_records > 0:\n",
    "            raise ValueError(f'There are LandAverageTemperature nulls in the {table_name} table.') \n",
    "            \n",
    "        if len(records2) < 1 or len(records2[0]) < 1:\n",
    "            raise ValueError(f\"Data quality check failed. The {table_name} table might have no data.\")\n",
    "        \n",
    "        num_records = records2[0][0]        \n",
    "        if num_records > 0:\n",
    "            raise ValueError(f'There are LandAverageTemperatureUncertainty nulls in the {table_name} table.')   \n",
    "            \n",
    "        if len(duplicate) < 1 or len(duplicate[0]) < 1:\n",
    "            raise ValueError(f\"Data quality check failed. The {table_name} table might have no data.\")\n",
    "        \n",
    "        num_records = duplicate[0][0]        \n",
    "        if num_records > 0:\n",
    "            raise ValueError(f'There are duplicates in the {table_name} table.') \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here is an example of how the Airflow dag will be populated with the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "```python\n",
    "from airflow.operators import DataQualityOperator     \n",
    "\n",
    "run_quality_checks = DataQualityOperator(\n",
    "    task_id='global_check_nulls_and_duplicates',\n",
    "    dag=dag,\n",
    "    redshift_conn_id=\"redshift\",\n",
    "    table_name=\"spectrum.GlobalTemperatures\",\n",
    "    grouping=\"dt\"\n",
    ")\n",
    "\n",
    "run_quality_checks = DataQualityOperator(\n",
    "    task_id='country_check_nulls_and_duplicates',\n",
    "    dag=dag,\n",
    "    redshift_conn_id=\"redshift\",\n",
    "    table_name=\"spectrum.GlobalLandTemperaturesByCountry\",\n",
    "    grouping=\"dt, Country\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Data Dictionary:**\n",
    "\n",
    "- Glue database: production \n",
    "- Glueu and Redshift table name: global_temperatures\n",
    "- Redshift database: operations\n",
    "- Redshift schema: prod\n",
    "\n",
    "|column|details|\n",
    "|-|-|\n",
    "|dt|the date the senesor measured the temperature|\n",
    "|LandAverageTemperature|the global average temperature of the land in overall|\n",
    "|LandAverageTemperatureUncertainty|the global uncertainty aournd the average temperature of the land|\n",
    "\n",
    "---\n",
    "- Glue database: production\n",
    "- Glue and Redshift table name: bycountry_temperatures\n",
    "- Redshift database: operations\n",
    "- Redshift schema: prod\n",
    "\n",
    "|column|details|\n",
    "|-|-|\n",
    "|dt|the date the senesor measured the temperature|\n",
    "|Country|the country in which the temperature was taken from|\n",
    "|LandAverageTemperature|the country average temperature of the land in overall|\n",
    "|LandAverageTemperatureUncertainty|the country uncertainty aournd the average temperature of the land|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "!rm sas_data -r -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
