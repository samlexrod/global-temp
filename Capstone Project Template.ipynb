{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Pipeline of Global Wold Temperatures\n",
    "## Data Engineering Capstone Project\n",
    "---\n",
    "\n",
    "### Project Summary\n",
    "> In this project, I am going to provide details about how I would create an AWS etl pipeline for global wold temperatures of data gathered from Kaggle.com.\n",
    "\n",
    "The project follows these steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Installations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "# !pip install kaggle \n",
    "# !pip install twine\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# pyspark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# starting spark application\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "<hr style=\"border-top: 3px double\">\n",
    "Explain what you plan to do in the project in more detail. \n",
    "\n",
    "##### <u>Development Scope</u>\n",
    "In the development phase, i will use the [Wold Temperature Data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) from kaggle. The data will be stored in S3, converted to parquet file for efficient spark processing, and explored in AWS EMR. After exploration, I will design a cleaning script to handle any usual transformations that can be done to clean the data.\n",
    "\n",
    "\n",
    "##### <u>Production Scope</u>\n",
    "\n",
    "In the production phase, i will use the raw data from the source of truth, which is berkeleyearth.org. We will use AWS Lambda function to gather the data, the EMR to process the cleaning and transformation, and Redshift Spectrum to read the S3 parquet files to connected with either PowerBI or Quicksight for downstream consumption.\n",
    "\n",
    "#### Description of Data\n",
    "<hr style=\"border-top: 2px double\">\n",
    "\n",
    "As they explain in Kaggle, Berkeley Earth Surface Temperature Study combines 1.6 billion temperature reports from 16 pre-existing archives.\n",
    "\n",
    "Global Land and Ocean-and-Land Temperatures (GlobalTemperatures.csv):\n",
    "\n",
    "- Date: starts in 1750 for average land temperature and 1850 for max and min land temperatures and global ocean and land temperatures\n",
    "- LandAverageTemperature: global average land temperature in celsius\n",
    "- LandAverageTemperatureUncertainty: the 95% confidence interval around the average\n",
    "- LandMaxTemperature: global average maximum land temperature in celsius\n",
    "- LandMaxTemperatureUncertainty: the 95% confidence interval around the maximum land temperature\n",
    "- LandMinTemperature: global average minimum land temperature in celsius\n",
    "- LandMinTemperatureUncertainty: the 95% confidence interval around the minimum land temperature\n",
    "- LandAndOceanAverageTemperature: global average land and ocean temperature in celsius\n",
    "- LandAndOceanAverageTemperatureUncertainty: the 95% confidence interval around the global average land and ocean temperature\n",
    "\n",
    "Other files are provided in the following groupings:\n",
    "- Country\n",
    "- State\n",
    "- Major City\n",
    "- City\n",
    "\n",
    "#### Data Gathering \n",
    "<hr style=\"border-top: 2px double\">\n",
    "\n",
    "##### <u>Development Data Gathering</u>\n",
    "The data will be downloaded from Kaggle.com from theri kaggle cli API for this development process. \n",
    "\n",
    "To connect to the API, we must create a token. This token will allow programatic download of the data in a zip compression format.\n",
    "\n",
    "> An API token was created generating a kaggle.json file. This file was uploaded to /home/workspace\n",
    "\n",
    "##### <u>Production Data Gathering</u>\n",
    "\n",
    "The production version of data gathering will be in an AWS Lambda function that will crawl the lastest data from http://berkeleyearth.org. The flow of the data will be as following:\n",
    "\n",
    "1. AWS Lambda to crawl the latest raw data.\n",
    "1. EMR to read the data from s3 and perform cleaning and transformations\n",
    "\n",
    "At this point data will be ready for exploration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Gathering the Data for Development\n",
    "<hr style=\"border-top: 2px double\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reset directory and raw content\n",
    "!rm world-temp-data -r -f\n",
    "!rm climate-change-earth-surface-temperature-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create credential folder\n",
    "!mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the file with token was manualy uploaded\n",
    "!mv /home/workspace/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# securing file to only owner read and write\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                          title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "-----------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "berkeleyearth/climate-change-earth-surface-temperature-data  Climate Change: Earth Surface Temperature Data      85MB  2017-05-01 17:29:10          50415       1057  0.7647059        \n",
      "sumanthvrao/daily-climate-time-series-data                   Daily Climate time series data                      22KB  2019-08-23 09:22:09           1450         32  1.0              \n",
      "theworldbank/world-bank-climate-change-data                  World Bank Climate Change Data                      42MB  2019-05-16 20:00:44           2102         66  0.7058824        \n",
      "jsphyg/weather-dataset-rattle-package                        Rain in Australia                                    4MB  2018-12-03 00:07:10          23291        469  1.0              \n",
      "econdata/climate-change                                      climate change                                       9KB  2019-12-27 05:04:56            251          9  0.5294118        \n",
      "crawford/agricultural-survey-of-african-farm-households      Agricultural Survey of African Farm Households       4MB  2017-07-20 18:07:44           2486         63  0.8235294        \n",
      "brankokokanovic/wiki-climate                                 Wiki climate                                         2MB  2018-10-11 22:37:21            111          2  0.6875           \n",
      "vanshjatana/monsoon-data                                     Climate Data                                       251KB  2018-11-29 06:53:22             60         13  0.29411766       \n",
      "brunotly/climate-change                                      Climate Change                                       1MB  2020-03-01 17:20:38             55          5  0.47058824       \n",
      "edqian/twitter-climate-change-sentiment-dataset              Twitter Climate Change Sentiment Dataset             2MB  2019-11-13 00:28:07            313         15  0.9411765        \n",
      "rainbowgirl/climate-data-toronto-19372018                    Climate Data Toronto 1937-2018                      31KB  2018-12-04 00:15:45            694         14  0.3529412        \n",
      "dbialer/svalbard-climate-19102017                            Svalbard Climate, 1910-2017                          3KB  2017-09-11 20:54:24            208          8  0.7647059        \n",
      "noaa/global-historical-climatology-network                   Global Historical Climatology Network                5MB  2016-10-24 15:23:05           2059         51  0.7058824        \n",
      "reubencpereira/spatial-data-repo                             Spatial Data Repository (satellite data and more)   63MB  2018-05-15 18:46:08            715         32  0.7058824        \n",
      "aturner374/eighty-years-of-canadian-climate-data             Eighty years of Canadian climate data              991KB  2020-01-27 19:28:52            100          6  0.9117647        \n",
      "atulanandjha/temperature-readings-iot-devices                Temperature Readings : IOT Devices                   1MB  2019-12-01 18:48:54           1846         87  1.0              \n",
      "nsidcorg/daily-sea-ice-extent-data                           Daily Sea Ice Extent Data                          233KB  2019-06-10 18:42:01           2438         71  0.7647059        \n",
      "mathijs/weather-data-in-new-york-city-2016                   Weather data in New York City - 2016                 3KB  2017-09-24 18:06:20           5963         68  0.5882353        \n",
      "sohier/calcofi                                               CalCOFI                                             50MB  2017-08-23 19:24:53           8549        147  0.85294116       \n",
      "volpatto/temperature-timeseries-for-some-brazilian-cities    Temperature Time-Series for some Brazilian cities   27KB  2019-12-08 23:15:09           1412         57  0.9411765        \n",
      "/bin/sh: 1: change: not found\n"
     ]
    }
   ],
   "source": [
    "# listing datasets that contains climate and change\n",
    "!kaggle datasets list -s climate && change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading climate-change-earth-surface-temperature-data.zip to /home/workspace\n",
      " 91%|██████████████████████████████████▌   | 77.0M/84.7M [00:00<00:00, 94.0MB/s]\n",
      "100%|███████████████████████████████████████| 84.7M/84.7M [00:00<00:00, 150MB/s]\n"
     ]
    }
   ],
   "source": [
    "# downloading the zip file\n",
    "!kaggle datasets download -d berkeleyearth/climate-change-earth-surface-temperature-data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# unziping the downloaded file into wold_temp_date\n",
    "zip_file = ZipFile(\"climate-change-earth-surface-temperature-data.zip\", mode=\"r\")\n",
    "zip_file.extractall(\"world-temp-data/csv-files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Read all Flat File Datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- LandAverageTemperature: double (nullable = true)\n",
      " |-- LandAverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMaxTemperature: double (nullable = true)\n",
      " |-- LandMaxTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMinTemperature: double (nullable = true)\n",
      " |-- LandMinTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperature: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperatureUncertainty: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_global = spark.read.csv(\"world-temp-data/csv-files/GlobalTemperatures.csv\", header=True, inferSchema=True)\n",
    "df_global.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_bycity = spark.read.csv(\"world-temp-data/csv-files/GlobalLandTemperaturesByCity.csv\", header=True, inferSchema=True)\n",
    "df_bycountry = spark.read.csv(\"world-temp-data/csv-files/GlobalLandTemperaturesByCountry.csv\", header=True, inferSchema=True)\n",
    "df_bymajorcity = spark.read.csv(\"world-temp-data/csv-files/GlobalLandTemperaturesByMajorCity.csv\", header=True, inferSchema=True)\n",
    "df_bystate = spark.read.csv(\"world-temp-data/csv-files/GlobalLandTemperaturesByState.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Showing and Explaining the Individual Datasets\n",
    "<hr style=\"border-top: 2px double\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <ol style=\"display: inline-block\"><li> Global Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>1750-01-01 00:00:00</td>\n",
       "      <td>1750-02-01 00:00:00</td>\n",
       "      <td>1750-03-01 00:00:00</td>\n",
       "      <td>1750-04-01 00:00:00</td>\n",
       "      <td>1750-05-01 00:00:00</td>\n",
       "      <td>1750-06-01 00:00:00</td>\n",
       "      <td>1750-07-01 00:00:00</td>\n",
       "      <td>1750-08-01 00:00:00</td>\n",
       "      <td>1750-09-01 00:00:00</td>\n",
       "      <td>1750-10-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandAverageTemperature</th>\n",
       "      <td>3.034</td>\n",
       "      <td>3.083</td>\n",
       "      <td>5.626</td>\n",
       "      <td>8.49</td>\n",
       "      <td>11.573</td>\n",
       "      <td>12.937</td>\n",
       "      <td>15.868</td>\n",
       "      <td>14.75</td>\n",
       "      <td>11.413</td>\n",
       "      <td>6.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandAverageTemperatureUncertainty</th>\n",
       "      <td>3.574</td>\n",
       "      <td>3.702</td>\n",
       "      <td>3.076</td>\n",
       "      <td>2.451</td>\n",
       "      <td>2.072</td>\n",
       "      <td>1.724</td>\n",
       "      <td>1.911</td>\n",
       "      <td>2.231</td>\n",
       "      <td>2.637</td>\n",
       "      <td>2.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandMaxTemperature</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandMaxTemperatureUncertainty</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandMinTemperature</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandMinTemperatureUncertainty</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandAndOceanAverageTemperature</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandAndOceanAverageTemperatureUncertainty</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             0  \\\n",
       "dt                                         1750-01-01 00:00:00   \n",
       "LandAverageTemperature                                   3.034   \n",
       "LandAverageTemperatureUncertainty                        3.574   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             1  \\\n",
       "dt                                         1750-02-01 00:00:00   \n",
       "LandAverageTemperature                                   3.083   \n",
       "LandAverageTemperatureUncertainty                        3.702   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             2  \\\n",
       "dt                                         1750-03-01 00:00:00   \n",
       "LandAverageTemperature                                   5.626   \n",
       "LandAverageTemperatureUncertainty                        3.076   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             3  \\\n",
       "dt                                         1750-04-01 00:00:00   \n",
       "LandAverageTemperature                                    8.49   \n",
       "LandAverageTemperatureUncertainty                        2.451   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             4  \\\n",
       "dt                                         1750-05-01 00:00:00   \n",
       "LandAverageTemperature                                  11.573   \n",
       "LandAverageTemperatureUncertainty                        2.072   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             5  \\\n",
       "dt                                         1750-06-01 00:00:00   \n",
       "LandAverageTemperature                                  12.937   \n",
       "LandAverageTemperatureUncertainty                        1.724   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             6  \\\n",
       "dt                                         1750-07-01 00:00:00   \n",
       "LandAverageTemperature                                  15.868   \n",
       "LandAverageTemperatureUncertainty                        1.911   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             7  \\\n",
       "dt                                         1750-08-01 00:00:00   \n",
       "LandAverageTemperature                                   14.75   \n",
       "LandAverageTemperatureUncertainty                        2.231   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             8  \\\n",
       "dt                                         1750-09-01 00:00:00   \n",
       "LandAverageTemperature                                  11.413   \n",
       "LandAverageTemperatureUncertainty                        2.637   \n",
       "LandMaxTemperature                                        None   \n",
       "LandMaxTemperatureUncertainty                             None   \n",
       "LandMinTemperature                                        None   \n",
       "LandMinTemperatureUncertainty                             None   \n",
       "LandAndOceanAverageTemperature                            None   \n",
       "LandAndOceanAverageTemperatureUncertainty                 None   \n",
       "\n",
       "                                                             9  \n",
       "dt                                         1750-10-01 00:00:00  \n",
       "LandAverageTemperature                                   6.367  \n",
       "LandAverageTemperatureUncertainty                        2.668  \n",
       "LandMaxTemperature                                        None  \n",
       "LandMaxTemperatureUncertainty                             None  \n",
       "LandMinTemperature                                        None  \n",
       "LandMinTemperatureUncertainty                             None  \n",
       "LandAndOceanAverageTemperature                            None  \n",
       "LandAndOceanAverageTemperatureUncertainty                 None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_global.limit(10).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> This dataset describes the global temperatures on a time series basis. It also includes descriptive and inferential statistics about the global average. It is useful to compare global temperatures with temperatures by country to find countries that are outliers in our analysis of climate change.\n",
    "<hr style=\"border-top: 2px dotted; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <ol start=\"2\" style=\"display: inline-block\"><li> By City Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01 00:00:00|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bycity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> This dataset describes the global temperatures by city. It can be used to forecast the temperatures by city or to investigate global temperature abnormalies by city.\n",
    "<hr style=\"border-top: 2px dotted; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <ol start=\"3\" style=\"display: inline-block\"><li>By Country Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty|Country|\n",
      "+-------------------+------------------+-----------------------------+-------+\n",
      "|1743-11-01 00:00:00|4.3839999999999995|                        2.294|  Åland|\n",
      "|1743-12-01 00:00:00|              null|                         null|  Åland|\n",
      "|1744-01-01 00:00:00|              null|                         null|  Åland|\n",
      "|1744-02-01 00:00:00|              null|                         null|  Åland|\n",
      "|1744-03-01 00:00:00|              null|                         null|  Åland|\n",
      "+-------------------+------------------+-----------------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bycountry.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> This dataset describes the global temperatures by country. It can be used to forecast the temperatures by city or to investigate global temperature abnormalies by country.\n",
    "<hr style=\"border-top: 2px dotted; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <ol start=\"4\" style=\"display: inline-block\"><li>By Major City Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty|   City|      Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "|1849-01-01 00:00:00|            26.704|                        1.435|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-02-01 00:00:00|            27.434|                        1.362|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-03-01 00:00:00|            28.101|                        1.612|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-04-01 00:00:00|             26.14|           1.3869999999999998|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-05-01 00:00:00|            25.427|                          1.2|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "+-------------------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bymajorcity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> This dataset describes the global temperatures by major city. It can be used to forecast the temperatures by city or to investigate global temperature abnormalies by major city.\n",
    "<hr style=\"border-top: 2px dotted; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <ol start=\"5\" style=\"display: inline-block\"><li>By State Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----+-------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty|State|Country|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+\n",
      "|1855-05-01 00:00:00|            25.544|                        1.171| Acre| Brazil|\n",
      "|1855-06-01 00:00:00|            24.228|                        1.103| Acre| Brazil|\n",
      "|1855-07-01 00:00:00|            24.371|                        1.044| Acre| Brazil|\n",
      "|1855-08-01 00:00:00|            25.427|                        1.073| Acre| Brazil|\n",
      "|1855-09-01 00:00:00|            25.675|                        1.014| Acre| Brazil|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bystate.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> This dataset describes the global temperatures by state. It can be used to forecast the temperatures by city or to investigate global temperature abnormalies by state.\n",
    "<hr style=\"border-top: 2px dotted; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Converting and Reading Parquet\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Converting CSV to Parquet \n",
    "Apache Parquet is a columnar file format that provides optimizations to speed up queries and is a far more efficient file format than CSV or JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_global.write.parquet(\"world-temp-data/parquet-files/GlobalTemperatures\", mode=\"overwrite\")\n",
    "df_bycity.write.parquet(\"world-temp-data/parquet-files/GlobalLandTemperaturesByCity\", mode=\"overwrite\")\n",
    "df_bycountry.write.parquet(\"world-temp-data/parquet-files/GlobalLandTemperaturesByCountry\", mode=\"overwrite\")\n",
    "df_bymajorcity.write.parquet(\"world-temp-data/parquet-files/GlobalLandTemperaturesByMajorCity\", mode=\"overwrite\")\n",
    "df_bystate.write.parquet(\"world-temp-data/parquet-files/GlobalLandTemperaturesByState\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_global = spark.read.parquet(\"world-temp-data/parquet-files/GlobalTemperatures\")\n",
    "df_bycity = spark.read.parquet(\"world-temp-data/parquet-files/GlobalLandTemperaturesByCity\")\n",
    "df_bycountry = spark.read.parquet(\"world-temp-data/parquet-files/GlobalLandTemperaturesByCountry\")\n",
    "df_bymajorcity = spark.read.parquet(\"world-temp-data/parquet-files/GlobalLandTemperaturesByMajorCity\")\n",
    "df_bystate = spark.read.parquet(\"world-temp-data/parquet-files/GlobalLandTemperaturesByState\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Exploring Parquet Data\n",
    "---\n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def explore(dataframe, show_affected=False):\n",
    "    \"\"\"\n",
    "    This function explores the transposed content of a dataset,\n",
    "    the schema, and the null percentages\n",
    "    \"\"\"\n",
    "    df = dataframe    \n",
    "    null_expr = [f\"SUM(CASE WHEN {x} IS NULL THEN 1 ELSE 0 END) AS null_{x}\" for x in df.columns]\n",
    "    df_pd = (\n",
    "        df.selectExpr(null_expr)\n",
    "            .toPandas()\n",
    "            .transpose()\n",
    "            .rename(columns={0: 'nulls'})\n",
    "            .assign(null_pct= lambda x: x.nulls / df.count())\n",
    "    )    \n",
    "    display(df_pd.style.format({'nulls': '{:d}', 'null_pct': '{:2.2%}'}))\n",
    "    df.printSchema()\n",
    "    \n",
    "    if show_affected:\n",
    "        (df.where(F.col('dt').isin(affected_dates))\n",
    "             .groupBy('dt')\n",
    "             .agg(\n",
    "                F.expr('sum(AverageTemperature) AS affectedAverageTemperature'),\n",
    "                F.expr('sum(AverageTemperatureUncertainty) AS affectedAverageTemperatureUncertainty')\n",
    "             ).orderBy(F.desc('dt'))\n",
    "        ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "affected_dates = df_global.where(F.col('LandAverageTemperature').isNull()).select('dt').collect()\n",
    "affected_dates = [x.asDict().get('dt') for x in affected_dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <ol start=\"1\" style=\"display: inline-block\"><li> Exploring Global Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_LandAverageTemperature</th> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row1_col0\" class=\"data row1 col0\" >12</td> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row1_col1\" class=\"data row1 col1\" >0.38%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_LandAverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row2_col0\" class=\"data row2 col0\" >12</td> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row2_col1\" class=\"data row2 col1\" >0.38%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002level0_row3\" class=\"row_heading level0 row3\" >null_LandMaxTemperature</th> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row3_col0\" class=\"data row3 col0\" >1200</td> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row3_col1\" class=\"data row3 col1\" >37.59%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002level0_row4\" class=\"row_heading level0 row4\" >null_LandMaxTemperatureUncertainty</th> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row4_col0\" class=\"data row4 col0\" >1200</td> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row4_col1\" class=\"data row4 col1\" >37.59%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002level0_row5\" class=\"row_heading level0 row5\" >null_LandMinTemperature</th> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row5_col0\" class=\"data row5 col0\" >1200</td> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row5_col1\" class=\"data row5 col1\" >37.59%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002level0_row6\" class=\"row_heading level0 row6\" >null_LandMinTemperatureUncertainty</th> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row6_col0\" class=\"data row6 col0\" >1200</td> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row6_col1\" class=\"data row6 col1\" >37.59%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002level0_row7\" class=\"row_heading level0 row7\" >null_LandAndOceanAverageTemperature</th> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row7_col0\" class=\"data row7 col0\" >1200</td> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row7_col1\" class=\"data row7 col1\" >37.59%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002level0_row8\" class=\"row_heading level0 row8\" >null_LandAndOceanAverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row8_col0\" class=\"data row8 col0\" >1200</td> \n",
       "        <td id=\"T_1cb4bafe_aabb_11ea_8366_0242ac120002row8_col1\" class=\"data row8 col1\" >37.59%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9c0e0957b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- LandAverageTemperature: double (nullable = true)\n",
      " |-- LandAverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMaxTemperature: double (nullable = true)\n",
      " |-- LandMaxTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandMinTemperature: double (nullable = true)\n",
      " |-- LandMinTemperatureUncertainty: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperature: double (nullable = true)\n",
      " |-- LandAndOceanAverageTemperatureUncertainty: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <ol start=\"2\" style=\"display: inline-block\"><li> Exploring By City Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_220e8804_aabb_11ea_8366_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_220e8804_aabb_11ea_8366_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_220e8804_aabb_11ea_8366_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_AverageTemperature</th> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row1_col0\" class=\"data row1 col0\" >364130</td> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row1_col1\" class=\"data row1 col1\" >4.23%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_220e8804_aabb_11ea_8366_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_AverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row2_col0\" class=\"data row2 col0\" >364130</td> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row2_col1\" class=\"data row2 col1\" >4.23%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_220e8804_aabb_11ea_8366_0242ac120002level0_row3\" class=\"row_heading level0 row3\" >null_City</th> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row3_col0\" class=\"data row3 col0\" >0</td> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row3_col1\" class=\"data row3 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_220e8804_aabb_11ea_8366_0242ac120002level0_row4\" class=\"row_heading level0 row4\" >null_Country</th> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row4_col0\" class=\"data row4 col0\" >0</td> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row4_col1\" class=\"data row4 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_220e8804_aabb_11ea_8366_0242ac120002level0_row5\" class=\"row_heading level0 row5\" >null_Latitude</th> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row5_col0\" class=\"data row5 col0\" >0</td> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row5_col1\" class=\"data row5 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_220e8804_aabb_11ea_8366_0242ac120002level0_row6\" class=\"row_heading level0 row6\" >null_Longitude</th> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row6_col0\" class=\"data row6 col0\" >0</td> \n",
       "        <td id=\"T_220e8804_aabb_11ea_8366_0242ac120002row6_col1\" class=\"data row6 col1\" >0.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9bdfffc6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|                 dt|affectedAverageTemperature|affectedAverageTemperatureUncertainty|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|1752-09-01 00:00:00|                      null|                                 null|\n",
      "|1752-08-01 00:00:00|                      null|                                 null|\n",
      "|1752-07-01 00:00:00|                      null|                                 null|\n",
      "|1752-06-01 00:00:00|                      null|                                 null|\n",
      "|1752-05-01 00:00:00|                      null|                                 null|\n",
      "|1752-02-01 00:00:00|                      null|                                 null|\n",
      "|1751-12-01 00:00:00|                      null|                                 null|\n",
      "|1751-11-01 00:00:00|                      null|                                 null|\n",
      "|1751-10-01 00:00:00|                      null|                                 null|\n",
      "|1751-07-01 00:00:00|        13374.689000000031|                    946.7930000000013|\n",
      "|1751-05-01 00:00:00|                      null|                                 null|\n",
      "|1750-11-01 00:00:00|                      null|                                 null|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_bycity, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <ol start=\"3\" style=\"display: inline-block\"><li> Exploring By Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_AverageTemperature</th> \n",
       "        <td id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002row1_col0\" class=\"data row1 col0\" >32651</td> \n",
       "        <td id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002row1_col1\" class=\"data row1 col1\" >5.65%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_AverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002row2_col0\" class=\"data row2 col0\" >31912</td> \n",
       "        <td id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002row2_col1\" class=\"data row2 col1\" >5.53%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002level0_row3\" class=\"row_heading level0 row3\" >null_Country</th> \n",
       "        <td id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002row3_col0\" class=\"data row3 col0\" >0</td> \n",
       "        <td id=\"T_5c4885b0_aabb_11ea_8366_0242ac120002row3_col1\" class=\"data row3 col1\" >0.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9be427fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|                 dt|affectedAverageTemperature|affectedAverageTemperatureUncertainty|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|1752-09-01 00:00:00|                      null|                                 null|\n",
      "|1752-08-01 00:00:00|                      null|                                 null|\n",
      "|1752-07-01 00:00:00|                      null|                                 null|\n",
      "|1752-06-01 00:00:00|                      null|                                 null|\n",
      "|1752-05-01 00:00:00|                      null|                                 null|\n",
      "|1752-02-01 00:00:00|                      null|                                 null|\n",
      "|1751-12-01 00:00:00|                      null|                                 null|\n",
      "|1751-11-01 00:00:00|                      null|                                 null|\n",
      "|1751-10-01 00:00:00|                      null|                                 null|\n",
      "|1751-07-01 00:00:00|         905.6660000000003|                               94.739|\n",
      "|1751-05-01 00:00:00|                      null|                                 null|\n",
      "|1750-11-01 00:00:00|                      null|                                 null|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_bycountry, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <ol start=\"4\" style=\"display: inline-block\"><li> Exploring By Major City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_AverageTemperature</th> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row1_col0\" class=\"data row1 col0\" >11002</td> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row1_col1\" class=\"data row1 col1\" >4.60%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_AverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row2_col0\" class=\"data row2 col0\" >11002</td> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row2_col1\" class=\"data row2 col1\" >4.60%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002level0_row3\" class=\"row_heading level0 row3\" >null_City</th> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row3_col0\" class=\"data row3 col0\" >0</td> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row3_col1\" class=\"data row3 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002level0_row4\" class=\"row_heading level0 row4\" >null_Country</th> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row4_col0\" class=\"data row4 col0\" >0</td> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row4_col1\" class=\"data row4 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002level0_row5\" class=\"row_heading level0 row5\" >null_Latitude</th> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row5_col0\" class=\"data row5 col0\" >0</td> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row5_col1\" class=\"data row5 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002level0_row6\" class=\"row_heading level0 row6\" >null_Longitude</th> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row6_col0\" class=\"data row6 col0\" >0</td> \n",
       "        <td id=\"T_60a0b5ce_aabb_11ea_8366_0242ac120002row6_col1\" class=\"data row6 col1\" >0.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9bdff887b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|                 dt|affectedAverageTemperature|affectedAverageTemperatureUncertainty|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|1752-09-01 00:00:00|                      null|                                 null|\n",
      "|1752-08-01 00:00:00|                      null|                                 null|\n",
      "|1752-07-01 00:00:00|                      null|                                 null|\n",
      "|1752-06-01 00:00:00|                      null|                                 null|\n",
      "|1752-05-01 00:00:00|                      null|                                 null|\n",
      "|1752-02-01 00:00:00|                      null|                                 null|\n",
      "|1751-12-01 00:00:00|                      null|                                 null|\n",
      "|1751-11-01 00:00:00|                      null|                                 null|\n",
      "|1751-10-01 00:00:00|                      null|                                 null|\n",
      "|1751-07-01 00:00:00|                   262.498|                               18.299|\n",
      "|1751-05-01 00:00:00|                      null|                                 null|\n",
      "|1750-11-01 00:00:00|                      null|                                 null|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_bymajorcity, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <ol start=\"5\" style=\"display: inline-block\"><li> Exploring By State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_63832ede_aabb_11ea_8366_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_63832ede_aabb_11ea_8366_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_63832ede_aabb_11ea_8366_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_63832ede_aabb_11ea_8366_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_63832ede_aabb_11ea_8366_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_AverageTemperature</th> \n",
       "        <td id=\"T_63832ede_aabb_11ea_8366_0242ac120002row1_col0\" class=\"data row1 col0\" >25648</td> \n",
       "        <td id=\"T_63832ede_aabb_11ea_8366_0242ac120002row1_col1\" class=\"data row1 col1\" >3.97%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_63832ede_aabb_11ea_8366_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_AverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_63832ede_aabb_11ea_8366_0242ac120002row2_col0\" class=\"data row2 col0\" >25648</td> \n",
       "        <td id=\"T_63832ede_aabb_11ea_8366_0242ac120002row2_col1\" class=\"data row2 col1\" >3.97%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_63832ede_aabb_11ea_8366_0242ac120002level0_row3\" class=\"row_heading level0 row3\" >null_State</th> \n",
       "        <td id=\"T_63832ede_aabb_11ea_8366_0242ac120002row3_col0\" class=\"data row3 col0\" >0</td> \n",
       "        <td id=\"T_63832ede_aabb_11ea_8366_0242ac120002row3_col1\" class=\"data row3 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_63832ede_aabb_11ea_8366_0242ac120002level0_row4\" class=\"row_heading level0 row4\" >null_Country</th> \n",
       "        <td id=\"T_63832ede_aabb_11ea_8366_0242ac120002row4_col0\" class=\"data row4 col0\" >0</td> \n",
       "        <td id=\"T_63832ede_aabb_11ea_8366_0242ac120002row4_col1\" class=\"data row4 col1\" >0.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9bdff93ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|                 dt|affectedAverageTemperature|affectedAverageTemperatureUncertainty|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "|1752-09-01 00:00:00|                      null|                                 null|\n",
      "|1752-08-01 00:00:00|                      null|                                 null|\n",
      "|1752-07-01 00:00:00|                      null|                                 null|\n",
      "|1752-06-01 00:00:00|                      null|                                 null|\n",
      "|1752-05-01 00:00:00|                      null|                                 null|\n",
      "|1752-02-01 00:00:00|                      null|                                 null|\n",
      "|1751-12-01 00:00:00|                      null|                                 null|\n",
      "|1751-11-01 00:00:00|                      null|                                 null|\n",
      "|1751-10-01 00:00:00|                      null|                                 null|\n",
      "|1751-07-01 00:00:00|        1443.5569999999996|                   210.96800000000005|\n",
      "|1751-05-01 00:00:00|                      null|                                 null|\n",
      "|1750-11-01 00:00:00|                      null|                                 null|\n",
      "+-------------------+--------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_bystate, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Analsysis**\n",
    "> There are too many nulls in other than LandAverageTemperature and LandAverageTemperatureUncertainty. For our analysis there is also no use for the other columns. Therefore, those columns will be ignored.\n",
    "\n",
    "> Using the same affected dates to impute missing values to the global dataset from grouped datasets will not work since they are affected the same way. Regardless, the addition of the averages will not equal the true missing global average.\n",
    "\n",
    "> For LandAverageTemperature and LandAverageTemperatureUncertainty, we will use the average of the previous values and the next values that approximate the affected nulled ranges. E.g. if the current null value is followed by 2 nulls, we will use the next 3 values and the last 3 values to calculate the average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Cleaning Stage\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The globaltemperatures dataset seems to be fairly clean. However, these are averages, and we still have the questions if the averages are representable of all countries and states within those countries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Imputation if Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_global.createOrReplaceTempView('globaltemps')\n",
    "\n",
    "df_global_clean = spark.sql(\"\"\"\n",
    "WITH cte_null_impute AS (\n",
    "SELECT\n",
    "    dt\n",
    "    ,LandAverageTemperature\n",
    "    ,AVG(LandAverageTemperature) OVER(ORDER BY dt ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING) AS preced_follow_avgtemp\n",
    "    ,LandAverageTemperatureUncertainty\n",
    "    ,AVG(LandAverageTemperatureUncertainty) OVER(ORDER BY dt ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING) AS preced_follow_avgunctemp\n",
    "FROM globaltemps\n",
    ")\n",
    "SELECT \n",
    "    dt\n",
    "    ,COALESCE(LandAverageTemperature, preced_follow_avgtemp) AS LandAverageTemperature\n",
    "    ,COALESCE(LandAverageTemperatureUncertainty, preced_follow_avgunctemp) AS LandAverageTemperatureUncertainty\n",
    "FROM cte_null_impute\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_a29abc22_aabb_11ea_8366_0242ac120002\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >nulls</th> \n",
       "        <th class=\"col_heading level0 col1\" >null_pct</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_a29abc22_aabb_11ea_8366_0242ac120002level0_row0\" class=\"row_heading level0 row0\" >null_dt</th> \n",
       "        <td id=\"T_a29abc22_aabb_11ea_8366_0242ac120002row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_a29abc22_aabb_11ea_8366_0242ac120002row0_col1\" class=\"data row0 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a29abc22_aabb_11ea_8366_0242ac120002level0_row1\" class=\"row_heading level0 row1\" >null_LandAverageTemperature</th> \n",
       "        <td id=\"T_a29abc22_aabb_11ea_8366_0242ac120002row1_col0\" class=\"data row1 col0\" >0</td> \n",
       "        <td id=\"T_a29abc22_aabb_11ea_8366_0242ac120002row1_col1\" class=\"data row1 col1\" >0.00%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_a29abc22_aabb_11ea_8366_0242ac120002level0_row2\" class=\"row_heading level0 row2\" >null_LandAverageTemperatureUncertainty</th> \n",
       "        <td id=\"T_a29abc22_aabb_11ea_8366_0242ac120002row2_col0\" class=\"data row2 col0\" >0</td> \n",
       "        <td id=\"T_a29abc22_aabb_11ea_8366_0242ac120002row2_col1\" class=\"data row2 col1\" >0.00%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9bdff8cd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- LandAverageTemperature: double (nullable = true)\n",
      " |-- LandAverageTemperatureUncertainty: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore(df_global_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "![conceptual data model](resources/udacity-dend-datamodel.png)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Data is crawled form original  http://berkeleyearth.org website using AWS Lambda\n",
    "2. Data is dumped into a s3 bucket in Json format in s3://udacity-dend-samuel/raw-data\n",
    "3. Data is read using a spark cluster using pyspark and converted into parquet in s3://udacity-dend-samuel/staging-data\n",
    "4. Data is read using a spark cluster using pyspark and transformed/cleaned\n",
    "5. Data is check for null values and duplicates using a spark cluster\n",
    "6. Quality checks are conducted:\n",
    "    a. If data pass all quality checks, it is dumped into into s3://udacity-dend-samuel/clean-data as parquet\n",
    "    b. If data does not pass quality checks, the error is sent by email to users and the process stops\n",
    "7. A Glue crawler catalogs the parquet files in s3://udacity-dend-samuel/clean-data as parquet in the Glue global_temp database\n",
    "8. Redshift Spectrum refers to the clean-data table in the global_temp database in a global_temp_db redshift database\n",
    "9. Power BI connects to Redshift and extracts the clean-data table from the global_temp_db using a Redshift Driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 1: AWS Lmabda Crawler\n",
    "> We are extracting data from the website using a Python web scraping techniques. The outputs will be parsed as JSON documents that will be stored in S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 2: Glue Spark Job or EMR Spark Job to Read JSON\n",
    "> The JSON data will be read using spark into a spark dataframe in EMR memory. This task is separated from the rest because we would like to know if the JSON file schema was created correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o64.json.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:547)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:355)\n\tat org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:391)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101)\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193)\n\t... 30 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4cf77d13f5ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Reading data from s3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3a://udacity-dend-samuel/raw-data/global-temperatures.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, path, schema, primitivesAsString, prefersDecimal, allowComments, allowUnquotedFieldNames, allowSingleQuotes, allowNumericLeadingZero, allowBackslashEscapingAnyCharacter, mode, columnNameOfCorruptRecord, dateFormat, timestampFormat, multiLine, allowUnquotedControlChars, lineSep, samplingRatio, dropFieldIfAllNull, encoding)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o64.json.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:547)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:355)\n\tat org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:391)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101)\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193)\n\t... 30 more\n"
     ]
    }
   ],
   "source": [
    "## Reading data from s3\n",
    "df = spark.read.json(\"s3a://udacity-dend-samuel/raw-data/global-temperatures.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 3: Glue Spark Job or EMR Spark Job to Convert to Parquet\n",
    "> The EMR dataframe in memory is then converted to parquet to consume less resources when conducting transformations and cleaning activities. This step is separated from the rest because we would like to know if the transformation was succesful and the cleaning script runs without any issues. It would also let us know if we have already extracted the same date by the partition provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8a78cccca036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Converting data into parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'extraction_date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3a://udacity-samuel-projects/dend-campstone/parquet-staging/GlobalTemperatures\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "## Converting data into parquet\n",
    "df.write.partitionBy('extraction_date').parquet(\"s3a://udacity-dend-samuel/staging-data/global-temperatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 4: Glue Spark or EMR Job to Read Parquet and Clean Data\n",
    "> We are reading the parquet files and conducting the cleaning on parquet data since it is more efficient. This task will conbine reading parquet and celaning because we are not expecting the reading part to fail. On the contrary, we can expect the cleaning part to fail. Therefore we will know that the cleaning script needs to be evaluated for quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Reading parquet file\n",
    "# df = spark.read.parquet(\"s3a://udacity-dend-samuel/staging-data/global-temperatures\")\n",
    "df = df_global\n",
    "\n",
    "## Cleaning parquet file\n",
    "df.createOrReplaceTempView('staging')\n",
    "\n",
    "df = spark.sql(\"\"\"\n",
    "WITH cte_null_impute AS (\n",
    "SELECT\n",
    "    dt\n",
    "    ,LandAverageTemperature\n",
    "    ,AVG(LandAverageTemperature) OVER(ORDER BY dt ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING) AS preced_follow_avgtemp\n",
    "    ,LandAverageTemperatureUncertainty\n",
    "    ,AVG(LandAverageTemperatureUncertainty) OVER(ORDER BY dt ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING) AS preced_follow_avgunctemp\n",
    "FROM staging\n",
    ")\n",
    "SELECT \n",
    "    dt\n",
    "    ,COALESCE(LandAverageTemperature, preced_follow_avgtemp) AS LandAverageTemperature\n",
    "    ,COALESCE(LandAverageTemperatureUncertainty, preced_follow_avgunctemp) AS LandAverageTemperatureUncertainty\n",
    "FROM cte_null_impute\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 5: Glue Spark Job or EMR Spark Job to Check for Nulls and Duplicates\n",
    "> In this task we are doing to determine if the data is ready for downstream consumption and meets the quality requirements agreed. It is a separate task because we need to make sure that our downstream users are not consuming the wrong data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## conduct null data quality\n",
    "column_wide_null_count = sum(df.selectExpr(\n",
    "    \"CASE WHEN LandAverageTemperature IS NULL THEN 1 ELSE 0 END AS null_LandAverageTemperature\",\n",
    "    \"CASE WHEN LandAverageTemperatureUncertainty IS NULL THEN 1 ELSE 0 END AS null_LandAverageTemperatureUncertainty\").collect()[0])\n",
    "\n",
    "## conduct duplicate data quality\n",
    "duplicate_count = df.groupBy('dt').agg((F.count('dt')>1).alias('group_count')).where(F.col('group_count')).count()\n",
    "\n",
    "error_list = []\n",
    "if column_wide_null_count > 0:\n",
    "    error_list.append(\"Null where found in the data\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    error_list.append(\"Duplicates where found in the data\")\n",
    "    \n",
    "if len(error_list) > 0:\n",
    "    raise ValueError(' and '.join(error_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Dag Task 6: Glue Spark Job or EMR Spark Job to Dump Clean Data and Crawled for Downstream\n",
    "> Here we are dumping the data that passess quality checks into the final bucket that will be catalogued using Glue and read using Redshift Spectrum as the endpoint of the visualization tool.\n",
    "\n",
    "> A Glue crawler will catalog the clean data after it is dumped in the destination s3 object/key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Dumping clean dataset into the clean key\n",
    "df.write.parquet(\"s3a://udacity-dend-samuel/clean-data/global-temperatures\")\n",
    "\n",
    "# Done! Data is ready for visualization and forecasting model ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "\n",
    "> The data will be checked right after the data is cleaned. We are preventing bad data from being dumped in the s3://udacity-dend-samuel/clean-data/global-temperatures file key.\n",
    "\n",
    "Thes checks include:\n",
    "* Null checks for both LandAverageTemperature and LandAverageTemperatureUncertainty\n",
    "* Duplicate checks on dt\n",
    "\n",
    "> Another worthy quality check is to make sure data is catalogued in Glue. This one will run in Redshift Sepctrum and it will check for the quantity of rows in the prod.global_temperatures table that Redshift Spectrum reads from the s3://udacity-dend-samuel/clean-data/global-temperatures file key using the Glue catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here is an example of how the data quality operator will look:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "airflow/operators.py\n",
    "```python\n",
    "from airflow.hooks.postgres_hook import PostgresHook\n",
    "from airflow.models import BaseOperator\n",
    "from airflow.utils.decorators import apply_defaults\n",
    "\n",
    "class DataQualityOperator(BaseOperator):\n",
    "    ui_color = '#89DA59'\n",
    "\n",
    "    @apply_defaults\n",
    "    def __init__(self,\n",
    "                 redshift_conn_id=\"\",\n",
    "                 table_name=\"\",\n",
    "                 sql_dict=\"\",\n",
    "                 *args, **kwargs):\n",
    "\n",
    "        super(DataQualityOperator, self).__init__(*args, **kwargs)\n",
    "        self.redshift_conn_id = redshift_conn_id\n",
    "        self.table_name = table_name\n",
    "\n",
    "    def execute(self, context):\n",
    "        redshift = PostgresHook(postgres_conn_id=self.redshift_conn_id)\n",
    "        table_name = self.table_name\n",
    "        CATALOG_SUCCESFUL = f\"\"\"\n",
    "            SELECT count(*)\n",
    "            FROM {table_name}\n",
    "            \"\"\"\n",
    "        \n",
    "        self.log.info(f\"Conducting data quality on table {table_name}\")\n",
    "        records = redshift.get_records(CATALOG_SUCCESFUL)\n",
    "        \n",
    "        if len(records) < 1 or len(records[0]) < 1:\n",
    "            raise ValueError(f\"Data quality check failed. The {table_name} table might not exist.\")\n",
    "        \n",
    "        num_records = records[0][0]        \n",
    "        if num_records = 0:\n",
    "            raise ValueError(f'The Glue data catalog have no data for {table_name}')   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here is an example of how the Airflow dag will be populated with the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "```python\n",
    "from airflow.operators import DataQualityOperator     \n",
    "\n",
    "run_quality_checks = DataQualityOperator(\n",
    "    task_id='Run_crawler_quality_checks',\n",
    "    dag=dag,\n",
    "    redshift_conn_id=\"redshift\",\n",
    "    table_name=\"prod.global_temperatures\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Data Dictionary:**\n",
    "\n",
    "- Glue database: production \n",
    "- Glueu and Redshift table name: global_temperatures\n",
    "- Redshift database: operations\n",
    "- Redshift schema: prod\n",
    "\n",
    "|column|details|\n",
    "|-|-|\n",
    "|dt|the date the senesor measured the temperature|\n",
    "|LandAverageTemperature|the global average temperature of the land in overall|\n",
    "|LandAverageTemperatureUncertainty|the global uncertainty aournd the average temperature of the land|\n",
    "\n",
    "---\n",
    "- Glue database: production\n",
    "- Glue and Redshift table name: bycountry_temperatures\n",
    "- Redshift database: operations\n",
    "- Redshift schema: prod\n",
    "\n",
    "|column|details|\n",
    "|-|-|\n",
    "|dt|the date the senesor measured the temperature|\n",
    "|Country|the country in which the temperature was taken from|\n",
    "|LandAverageTemperature|the country average temperature of the land in overall|\n",
    "|LandAverageTemperatureUncertainty|the country uncertainty aournd the average temperature of the land|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
